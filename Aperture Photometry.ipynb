{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "\n",
    "REALEST CODE OF ALL THE ONE TRUE CORRECT ONE\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats, sigma_clip\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.psf import fit_fwhm\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "import os\n",
    "\n",
    "# List of all reduced image paths.     \n",
    "reduced_image_paths = reduced_image_paths = [\n",
    "\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\M52\\B-band\\M52_normalized_Stacked_B-band.fits', 'M52_B'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\M52\\U-band\\M52_normalized_Stacked_U-band.fits', 'M52_U'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\M52\\V-band\\M52_normalized_Stacked_V-band.fits', 'M52_V'),\n",
    "\n",
    "\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\NGC7789\\B-band\\NGC7789_normalized_Stacked_B-band.fits', 'NGC7789_B'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\NGC7789\\U-band\\NGC7789_normalized_Stacked_U-band.fits', 'NGC7789_U'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\NGC7789\\V-band\\NGC7789_normalized_Stacked_V-band.fits', 'NGC7789_V'),\n",
    "\n",
    "    # # Standard Star 1 - B-band\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\B-band\\First Observation\\SS1 normalized_Stacked_First Observation B.fits', 'Standard_Star_1_B_1st'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\B-band\\Second Observation\\SS1 normalized_Stacked_Second Observation B.fits', 'Standard_Star_1_B_2nd'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\B-band\\Third Observation\\SS1 normalized_Stacked_Third Observation B.fits', 'Standard_Star_1_B_3rd'),\n",
    "\n",
    "    # Standard Star 1 - U-band\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\U-band\\First Observation\\SS1 normalized_Stacked_First Observation U.fits', 'Standard_Star_1_U_1st'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\U-band\\Second Observation\\SS1 normalized_Stacked_Second Observation U.fits', 'Standard_Star_1_U_2nd'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\U-band\\Third Observation\\SS1 normalized_Stacked_Third Observation U.fits', 'Standard_Star_1_U_3rd'),\n",
    "\n",
    "    # Standard Star 1 - V-band\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\V-band\\First Observation\\SS1 normalized_Stacked_First Observation V.fits', 'Standard_Star_1_V_1st'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\V-band\\Second Observation\\SS1 normalized_Stacked_Second Observation V.fits', 'Standard_Star_1_V_2nd'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 1\\V-band\\Third Observation\\SS1 normalized_Stacked_Third Observation V.fits', 'Standard_Star_1_V_3rd'),\n",
    "\n",
    "    # # Standard Star 2 - B-band\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\B-band\\First Observation\\SS2 normalized_Stacked_First Observation B.fits', 'Standard_Star_2_B_1st'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\B-band\\Second Observation\\SS2 normalized_Stacked_Second Observation B.fits', 'Standard_Star_2_B_2nd'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\B-band\\Third Observation\\SS2 normalized_Stacked_Third Observation B.fits', 'Standard_Star_2_B_3rd'),\n",
    "\n",
    "    # # Standard Star 2 - U-band\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\U-band\\First Observation\\SS2 normalized_Stacked_First Observation U.fits', 'Standard_Star_2_U_1st'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\U-band\\Second Observation\\SS2 normalized_Stacked_Second Observation U.fits', 'Standard_Star_2_U_2nd'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\U-band\\Third Observation\\SS2 normalized_Stacked_Third Observation U.fits', 'Standard_Star_2_U_3rd'),\n",
    "\n",
    "    # # # Standard Star 2 - V-band\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\V-band\\First Observation\\SS2 normalized_Stacked_First Observation V.fits', 'Standard_Star_2_V_1st'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\V-band\\Second Observation\\SS2 normalized_Stacked_Second Observation V.fits', 'Standard_Star_2_V_2nd'),\n",
    "    (r'G:\\MyProject\\TGP\\data_reduction\\Normalized Aligned Stacked Images\\Standard Star 2\\V-band\\Third Observation\\SS2 normalized_Stacked_Third Observation V.fits', 'Standard_Star_2_V_3rd'),\n",
    "]\n",
    "\n",
    "\n",
    "# Dictionary to store results for each image\n",
    "results = {}\n",
    "\n",
    "# Loop through each reduced image path\n",
    "for image_path, label in reduced_image_paths:\n",
    "    print(f\"Processing: {label}\")\n",
    "\n",
    "    # Ensure the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"File not found: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    with fits.open(image_path) as hdul:\n",
    "        data = hdul[0].data.astype(np.float32)  # convert to float32 to save memory\n",
    "        mean, median, std = sigma_clipped_stats(data, sigma=3.0)\n",
    "\n",
    "        # --- 1. First pass: initial FWHM guess ---\n",
    "        initial_fwhm_guess = 3.0\n",
    "        detection_threshold = 3.0 * std\n",
    "\n",
    "        daofind_init = DAOStarFinder(fwhm=initial_fwhm_guess, threshold=detection_threshold)\n",
    "        sources_init = daofind_init(data - median)\n",
    "\n",
    "        if sources_init is None or len(sources_init) == 0:\n",
    "            print(f\"No sources found for {label} in first pass. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Filter out edge sources (example: 10-pixel border)\n",
    "        mask = (\n",
    "            (sources_init['xcentroid'] > 10) &\n",
    "            (sources_init['xcentroid'] < data.shape[1] - 10) &\n",
    "            (sources_init['ycentroid'] > 10) &\n",
    "            (sources_init['ycentroid'] < data.shape[0] - 10)\n",
    "        )\n",
    "        sources_init = sources_init[mask]\n",
    "\n",
    "        if len(sources_init) == 0:\n",
    "            print(f\"All detected sources were near edges for {label}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Sort initial sources by flux (descending)\n",
    "        sources_init.sort('flux', reverse=True)\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # Limit the number of stars used for FWHM measurement (1st pass)\n",
    "        # -------------------------------------------------------------\n",
    "        n_fwhm_stars_first_pass = 100  # e.g. measure FWHM on the top 100 brightest\n",
    "        top_sources_first_pass = sources_init[:n_fwhm_stars_first_pass]\n",
    "        xypos_init = np.transpose((top_sources_first_pass['xcentroid'],\n",
    "                                   top_sources_first_pass['ycentroid']))\n",
    "\n",
    "        try:\n",
    "            # Measure the FWHM from these top N stars\n",
    "            fwhm_values_init = fit_fwhm(data, xypos=xypos_init, fit_shape=7)\n",
    "\n",
    "            # Filter out non-converged fits\n",
    "            good_mask = np.isfinite(fwhm_values_init) & (fwhm_values_init > 0)\n",
    "            fwhm_values_init = fwhm_values_init[good_mask]\n",
    "\n",
    "            if len(fwhm_values_init) == 0:\n",
    "                print(f\"No valid FWHM fits for {label} in the first pass.\")\n",
    "                continue\n",
    "\n",
    "            fwhm_values_init_clipped = sigma_clip(fwhm_values_init, sigma=3.0, maxiters=5)\n",
    "            median_fwhm_init = np.median(fwhm_values_init_clipped[~fwhm_values_init_clipped.mask])\n",
    "            print(f\"{label}: First-pass median FWHM = {median_fwhm_init:.2f} pixels\")\n",
    "\n",
    "            # --- 2. Second pass: use measured FWHM for detection ---\n",
    "            daofind_refined = DAOStarFinder(fwhm=median_fwhm_init, threshold=detection_threshold)\n",
    "            sources = daofind_refined(data - median)\n",
    "\n",
    "            if sources is None or len(sources) == 0:\n",
    "                print(f\"No sources found for {label} in second pass. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Sort by flux again\n",
    "            sources.sort('flux', reverse=True)\n",
    "\n",
    "            # --------------------------------------------------------------\n",
    "            # Limit the number of stars used for the second FWHM measurement\n",
    "            # --------------------------------------------------------------\n",
    "            n_fwhm_stars_second_pass = 100\n",
    "            top_sources_second_pass = sources[:n_fwhm_stars_second_pass]\n",
    "            xypos_2pass = np.transpose((top_sources_second_pass['xcentroid'],\n",
    "                                        top_sources_second_pass['ycentroid']))\n",
    "\n",
    "            # Dynamically compute fit_shape for the second pass\n",
    "            fit_shape = int(round(1.5 * median_fwhm_init))\n",
    "            if fit_shape < 7:\n",
    "                fit_shape = 7\n",
    "            if fit_shape % 2 == 0:\n",
    "                fit_shape += 1\n",
    "\n",
    "            fwhm_values = fit_fwhm(data, xypos=xypos_2pass, fit_shape=fit_shape)\n",
    "\n",
    "            # Filter out invalid fits\n",
    "            good_mask = np.isfinite(fwhm_values) & (fwhm_values > 0)\n",
    "            fwhm_values = fwhm_values[good_mask]\n",
    "\n",
    "            if len(fwhm_values) == 0:\n",
    "                print(f\"No valid FWHM fits for {label} in second pass.\")\n",
    "                continue\n",
    "\n",
    "            fwhm_values_clipped = sigma_clip(fwhm_values, sigma=3.0, maxiters=5)\n",
    "            median_fwhm_clipped = np.median(fwhm_values_clipped[~fwhm_values_clipped.mask])\n",
    "            print(f\"{label} - Clipped Median FWHM (2nd pass): {median_fwhm_clipped:.2f} pixels\")\n",
    "\n",
    "            # --- Aperture Photometry ---\n",
    "            # We do photometry on ALL sources from the second pass, not just the top N\n",
    "            xypos_all = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "\n",
    "            aperture_radius = 3.0 * median_fwhm_clipped\n",
    "            inner_radius = 2.0 * aperture_radius\n",
    "            outer_radius = 3.0 * aperture_radius\n",
    "\n",
    "            apertures = CircularAperture(xypos_all, r=aperture_radius)\n",
    "            annulus_apertures = CircularAnnulus(xypos_all, r_in=inner_radius, r_out=outer_radius)\n",
    "\n",
    "            n_sky = annulus_apertures.area\n",
    "            n_pix = apertures.area\n",
    "            if n_sky <= n_pix:\n",
    "                print(f\"Warning: Increase annulus size for {label} to ensure n_sky > n_pix.\")\n",
    "\n",
    "            phot_table = aperture_photometry(data, apertures)\n",
    "            bkg_table = aperture_photometry(data, annulus_apertures)\n",
    "\n",
    "            bkg_mean = bkg_table['aperture_sum'] / annulus_apertures.area\n",
    "            phot_table['residual_aperture_sum'] = phot_table['aperture_sum'] - (bkg_mean * apertures.area)\n",
    "\n",
    "            # Filter out non-positive flux\n",
    "            positive_flux = phot_table['residual_aperture_sum'] > 0\n",
    "            phot_table = phot_table[positive_flux]\n",
    "\n",
    "            # Calculate instrumental magnitudes\n",
    "            phot_table['instrumental_mag'] = -2.5 * np.log10(phot_table['residual_aperture_sum'])\n",
    "\n",
    "            # Store final results\n",
    "            results[label] = phot_table[['id', 'xcenter', 'ycenter',\n",
    "                                         'residual_aperture_sum', 'instrumental_mag']]\n",
    "            print(f\"Photometry results for {label} stored.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {label}: {e}\")\n",
    "\n",
    "# Display results\n",
    "for label, result in results.items():\n",
    "    print(f\"\\nResults for {label}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save each set of results to a CSV file\n",
    "for label, photometry_data in results.items():\n",
    "    try:\n",
    "        # Convert photometry data (Astropy Table) to a Pandas DataFrame\n",
    "        df = photometry_data.to_pandas()\n",
    "\n",
    "        # Define the CSV filename using the label\n",
    "        csv_filename = f\"{label}_photometry_results.csv\"\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "        print(f\"Saved photometry results for {label} to {csv_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results for {label}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
